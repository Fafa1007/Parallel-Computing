[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Parallel Computing",
    "section": "",
    "text": "1 Git Hub\nhttps://github.com/Fafa1007/CA4",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Parallel Computing Practical</span>"
    ]
  },
  {
    "objectID": "Question 1.html",
    "href": "Question 1.html",
    "title": "2  Question 1",
    "section": "",
    "text": "2.1 Question 1\nUse a foreach loop to repeat 100 times:\nlibrary(doParallel)\n\nLoading required package: foreach\n\n\nLoading required package: iterators\n\n\nLoading required package: parallel\n\ncores &lt;- detectCores() - 1  # Use available cores minus 1\ncl &lt;- makeCluster(cores)\nregisterDoParallel(cl)\n\n\nresult &lt;- matrix(nrow=0, ncol = 2)\n\n# Put \"combine = rbind\"\nsystem.time({\n  results &lt;- foreach(i= 1:100,.combine = rbind) %dopar% {\n    y &lt;- rexp(100, rate = 1)\n    x_bar &lt;- mean(y)\n    s_square &lt;- var(y)\n    cbind(x_bar, s_square)\n  }\n})\n\n   user  system elapsed \n   0.07    0.02    0.14 \n\nhead(results)\n\n         x_bar  s_square\n[1,] 1.1276169 1.5390551\n[2,] 1.0648027 0.8851849\n[3,] 1.0358869 1.1800866\n[4,] 1.0634855 1.3651851\n[5,] 0.9811833 0.7115642\n[6,] 0.8711126 0.6338393",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Question 1</span>"
    ]
  },
  {
    "objectID": "Question 1.html#question-1",
    "href": "Question 1.html#question-1",
    "title": "2  Question 1",
    "section": "",
    "text": "generate a random sample from an exponential distribution with mean 1\ncalculate mean and variance\nrow-bind your results (rbind) (results = mean and variance).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Question 1</span>"
    ]
  },
  {
    "objectID": "Question 2.html",
    "href": "Question 2.html",
    "title": "3  Question 2",
    "section": "",
    "text": "3.1 Question 2\nUse the doParallel package and foreach to bootstrap the median for the galaxies data (in library MASS).\nIf the foreach function needs access to data or a function from a certain package, this can be done by adding the .packages='MASS' (for example) argument.\nHow does processing time compare to that of serial processing? If each iteration’s run time is small, relative to the amount of data that needs to be loaded and returned, parallel processing might not actually speed up the total run time. Bootstrapping is relatively small: draw a sample, calculate a statistic. It might only start making a difference if each chunk becomes large relatively to the overheads of data transfer. Experiment with this. Try doing 1000 bootstrap samples at a time instead of managing single bootstrap samples.\nlibrary(doParallel)\n\nWarning: package 'doParallel' was built under R version 4.4.3\n\n\nLoading required package: foreach\n\n\nWarning: package 'foreach' was built under R version 4.4.3\n\n\nLoading required package: iterators\n\n\nWarning: package 'iterators' was built under R version 4.4.3\n\n\nLoading required package: parallel\n\nlibrary(MASS)\n\ncores &lt;- detectCores() - 1  # Use available cores minus 1\ncl &lt;- makeCluster(cores)\nregisterDoParallel(cl)\n\nbootstrap_median &lt;- function(dat, N, B){\n  medians &lt;- foreach(i = 1:N, .packages = 'MASS', .combine = c) %dopar%   {\n    bootstrap &lt;- sample(B, size = length(dat), replace=TRUE)\n    median(bootstrap)\n  }\n  return(medians)\n}\n# Testing how the number of tasks affects run time\nelapsed_time &lt;- c()\ni &lt;- 1\nfor(j in seq(1, 1000, by = 100) ){\n  elapsed_time[i] &lt;- system.time({\n    bootstrap_median(galaxies, j, length(galaxies))\n    })[\"elapsed\"]\n  i &lt;- i+1\n}\nplot(x=seq(1, 1000, by = 100), y =elapsed_time, \nmain = \"Elapsed Time as we change the number \nof simulations or tasks available to complete\nfixing the amount of work each worker has to do\", \n     xlab = \"The number of tasks to complete\", \n     ylab = \"Elapsed Time\", type = \"b\")\nInterpretation: As we increase the number of tasks, the elapsed time increases i.e. runs slower. This means that the overhead costs of the parallelized code become more significant as the number of tasks grows\n# Testing how the size of each tasks affects run time\nelapsed_time &lt;- c()\ni &lt;- 1\nfor(j in seq(1, 1000, by = 100) ){\n  elapsed_time[i] &lt;- system.time({\n    bootstrap_median(galaxies, 10, j)\n    })[\"elapsed\"]\n  i &lt;- i+1\n}\nplot(x=seq(1, 1000, by = 100), y =elapsed_time, \nmain = \"Elapsed Time as we change the size of\neach task to be completed for each worker\nfixing the number of tasks\", \nxlab = \"The size of each bootstrap\", \nylab = \"Elapsed Time\", type = \"b\")\nInterpretation: As we increase the size of the tasks for each set of of workers, we see an initial decrease in elapsed time, however it increases later on due to overhead costs.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Question 2</span>"
    ]
  },
  {
    "objectID": "Question 3.html",
    "href": "Question 3.html",
    "title": "4  Question 3",
    "section": "",
    "text": "4.1 Question 3\nEstimate coverage of a percentile bootstrap confidence interval for the following scenario: sample of size 50 from an exponential distribution with mean 1.\nlibrary(doParallel)\n\nLoading required package: foreach\n\n\nLoading required package: iterators\n\n\nLoading required package: parallel\n\ncores &lt;- detectCores() - 1  # Use available cores minus 1\ncl &lt;- makeCluster(cores)\nregisterDoParallel(cl)\n\nset.seed(123)\n\nbootstrap_coverage &lt;- function(B,N){\n   true_mean &lt;- 1 # for exponential distribution true mean is lamda / rate\n  \n  suppressWarnings(count &lt;- foreach(i = 1:N, .combine=\"+\") %dopar% {\n    dat &lt;- rexp(50, rate = 1)\n    \n    bootstrap_means &lt;- replicate(B, mean(sample(dat,size=length(dat),replace = TRUE)))\n    \n    upper_ci &lt;- as.numeric(quantile(bootstrap_means, 0.975))\n    lower_ci &lt;- as.numeric(quantile(bootstrap_means, 0.025))\n    \n    ifelse(true_mean &gt; lower_ci & true_mean &lt; upper_ci, 1, 0)\n  })\n  coverage &lt;- count/N\n  return(coverage)\n}\n\nB &lt;- 50 # Number of bootstraps be task\nN &lt;- 10000 # Number of simulations\nsuppressWarnings(system.time(print(bootstrap_coverage( B, N)))) \n\n[1] 0.8912\n\n\n   user  system elapsed \n   6.61    0.91   10.38 \n\n# Coverage Probability (should be close to the 95%, our confidence interval )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Question 3</span>"
    ]
  },
  {
    "objectID": "Question 4.html",
    "href": "Question 4.html",
    "title": "5  Question 4",
    "section": "",
    "text": "5.1 Question 4\nThe package iterators provides several functions that can be used to create sequences for the foreach function. For example, the irnorm function creates an object that iterates over vectors of normally distributed random numbers. It is useful when you need to use random variables drawn from one distribution in an expression that is run in parallel.\nIn this exercise, use the foreach and irnorm functions to iterate over 3 vectors, each containing 5 random variables. Find the largest value in each vector, and print those largest values.\nBefore running the foreach function set the seed to 1234.\nlibrary(doParallel)\n\nWarning: package 'doParallel' was built under R version 4.4.3\n\n\nLoading required package: foreach\n\n\nWarning: package 'foreach' was built under R version 4.4.3\n\n\nLoading required package: iterators\n\n\nWarning: package 'iterators' was built under R version 4.4.3\n\n\nLoading required package: parallel\n\nset.seed(1234)\n\ncores &lt;- detectCores() - 1  # Use available cores minus 1\ncl &lt;- makeCluster(cores)\nregisterDoParallel(cl)\n\n\n# Use foreach to find the maximum in each vector\nsuppressWarnings(system.time(\nmax_values &lt;- foreach(i = 1:3, .combine = c) %dopar% {\n  library(iterators)\n  it &lt;- irnorm(1, count=5)\n  max(nextElem(it))  # Find max value in each vector\n}))\n\n   user  system elapsed \n    0.0     0.0     0.1 \n\nprint(matrix(max_values))\n\n           [,1]\n[1,] -1.8063992\n[2,]  0.3792976\n[3,] -0.4507810",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Question 4</span>"
    ]
  },
  {
    "objectID": "Question 5.html",
    "href": "Question 5.html",
    "title": "6  Question 5",
    "section": "",
    "text": "6.1 Question 5\nCompare run time between parLapply, foreach and replicate for the above problem.\nlibrary(iterators)\n\nWarning: package 'iterators' was built under R version 4.4.3\n\nlibrary(doParallel)\n\nWarning: package 'doParallel' was built under R version 4.4.3\n\n\nLoading required package: foreach\n\n\nWarning: package 'foreach' was built under R version 4.4.3\n\n\nLoading required package: parallel\n\nset.seed(1234)\n\ncores &lt;- detectCores() - 1  # Use available cores minus 1\ncl &lt;- makeCluster(cores)\nregisterDoParallel(cl)\n\n# Parallel Function\nparallel_apply &lt;-  function(i) {\n  library(iterators)\n  it &lt;- irnorm(1, count=5)\n  max(nextElem(it))\n}\n\n# Use foreach to find the maximum in each vector\nforeach_func &lt;- function(n){\n  max_values &lt;- foreach(i = 1:n, .combine = c) %dopar% {\n  library(iterators)\n  it &lt;- irnorm(1, count=5)\n  max(nextElem(it))\n}}\n\n# Use parLapply to find the maximum in each vector\nparLapply_func &lt;- function(n){\n  max_values &lt;- parLapply(cl, 1:n, parallel_apply)\n}\n\n# Use replicate to find the maximum in each vector\nreplicate_func &lt;- function (n){\n  max_values &lt;- replicate(n,parallel_apply(i=n))\n}\n# Testing how the number tasks affects run time for each function\nforeach_time &lt;- c()\nparLapply_time &lt;- c()\nreplicate_time &lt;- c()\n\nset.seed(1234)\n\nx &lt;- seq(1, 1000, by = 100)\ni &lt;- 1\nfor(n in x){\n  foreach_time[i] &lt;- system.time(foreach_func(n))[\"elapsed\"]\n  parLapply_time[i] &lt;- system.time(parLapply_func(n))[\"elapsed\"]\n  replicate_time[i] &lt;- system.time(replicate_func(n))[\"elapsed\"]\n  i &lt;- i+1\n}\n\ndf1 &lt;- data.frame(x=x, y=foreach_time, Group = \"foreach\")\ndf2 &lt;- data.frame(x=x, y=parLapply_time, Group = \"parLapply\")\ndf3 &lt;- data.frame(x=x, y=replicate_time, Group = \"replicate\")\ncombined_df &lt;- rbind(df1, df2, df3)\n\nlibrary(ggplot2)\nggplot(data = combined_df, aes(x = x, y = y, color = Group)) +\n  geom_line() +\n  labs(\n    title = \"Elapsed Times for foreach, parLapply, and replicate\nas the number of tasks increases\",\n    subtitle = \"Using irnorm vectors\", \n    x = \"Number of tasks\",\n    y = \"Elapsed Time\",\n    color = \"Method\"\n  ) +\n  scale_color_manual(\n    values = c(\"foreach\" = \"Red\", \"parLapply\" = \"Blue\", \"replicate\" = \"Green\")\n    )\nInterpretation: The foreach function is slower than both parLapply and replicate due to high parallelization overhead. While replicate is faster initially for small tasks, parLapply outperforms it as the number of tasks increases, thanks to better scalability and efficient workload distribution across cores. For large tasks, parLapply is the best choice, while replicate is more suitable for smaller, serial operations.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Question 5</span>"
    ]
  }
]